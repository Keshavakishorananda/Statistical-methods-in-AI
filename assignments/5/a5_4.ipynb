{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/keshava/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "# Download the words corpus if not already downloaded\n",
    "def get_wordslist():\n",
    "    nltk.download('words')\n",
    "\n",
    "    word_list = words.words()\n",
    "\n",
    "    np.random.shuffle(word_list)\n",
    "\n",
    "    word_list_100k = word_list[:100000]\n",
    "    \n",
    "    return word_list_100k\n",
    "\n",
    "\n",
    "def generate_images(word, width=256, height=64, font_size=36):\n",
    "    image = Image.new('L', (width, height), 255)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"DejaVuSansMono.ttf\", font_size)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    bbox = draw.textbbox((0, 0), word, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "    \n",
    "    x = (width - text_width) // 2\n",
    "    y = (height - text_height) // 2\n",
    "    \n",
    "    draw.text((x, y), word, font=font, fill=0)\n",
    "    \n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "word_list = get_wordslist()\n",
    "\n",
    "if not os.path.exists('../../data/external/WordImages'):\n",
    "    os.makedirs('../../data/external/WordImages')\n",
    "\n",
    "for i, word in enumerate(word_list):\n",
    "    image = generate_images(word)\n",
    "    Image.fromarray(image).save(f'../../data/external/WordImages/{word}.png')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 82128\n",
      "Validation set size: 10266\n",
      "Test set size: 10266\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class WordImagesDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, characters='ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789- '):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(root)\n",
    "        \n",
    "        self.char_to_idx = {char: idx + 1 for idx, char in enumerate(characters)}\n",
    "        self.idx_to_char = {idx: char for char, idx in self.char_to_idx.items()}\n",
    "    \n",
    "    def encode_label(self, label):\n",
    "        return torch.tensor([self.char_to_idx[char] for char in label], dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.root, self.images[idx])\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.images[idx].split('.')[0]\n",
    "        encoded_label = self.encode_label(label)\n",
    "        return image, encoded_label, len(encoded_label)\n",
    "\n",
    "# Transform for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = WordImagesDataset('../../data/external/WordImages', transform=transform)\n",
    "\n",
    "# Split the dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = (len(dataset) - train_size) // 2\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Collate function to handle variable-length labels\n",
    "def collate_fn(batch):\n",
    "    images, labels, label_lengths = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.cat(labels)\n",
    "    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n",
    "    return images, labels, label_lengths\n",
    "\n",
    "# Data loaders with collate function\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f'Training set size: {len(train_dataset)}')\n",
    "print(f'Validation set size: {len(val_dataset)}')\n",
    "print(f'Test set size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CRNN model\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_features=256, hidden_size=128, vocab_size=54, dropout_rate=0.3):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 64, num_features) \n",
    "        self.lstm = nn.LSTM(num_features, hidden_size, batch_first=True, bidirectional=True, dropout=dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size * 2, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.CNN(x)\n",
    "        x = x.view(batch_size, x.size(1), -1)\n",
    "        x = self.fc1(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Average Number of Correct Characters\n",
    "def calculate_correct_characters(preds, targets):\n",
    "    correct = 0\n",
    "    for pred, target in zip(preds, targets):\n",
    "        pred = [p for p in pred if p != 0]\n",
    "        target = [t.item() for t in target if t != 0]\n",
    "        correct += sum([1 if p == t else 0 for p, t in zip(pred, target)])\n",
    "    return correct\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train_ctc(model, train_loader, val_loader, optimizer, num_epochs=10):\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, targets, target_lengths in train_loader:\n",
    "            images, targets, target_lengths = images.to(device), targets.to(device), target_lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images).log_softmax(2).permute(1, 0, 2)\n",
    "            \n",
    "            input_lengths = torch.full(\n",
    "                size=(outputs.size(1),),\n",
    "                fill_value=outputs.size(0),\n",
    "                dtype=torch.long\n",
    "            ).to(device)\n",
    "\n",
    "            loss = ctc_loss(outputs, targets, input_lengths, target_lengths)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        total_correct_characters = 0\n",
    "        total_characters = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets, target_lengths in val_loader:\n",
    "                images, targets, target_lengths = images.to(device), targets.to(device), target_lengths.to(device)\n",
    "                outputs = model(images).log_softmax(2).permute(1, 0, 2)\n",
    "\n",
    "                # Calculate input lengths as before\n",
    "                input_lengths = torch.full(\n",
    "                    size=(outputs.size(1),),\n",
    "                    fill_value=outputs.size(0),\n",
    "                    dtype=torch.long\n",
    "                ).to(device)\n",
    "\n",
    "                loss = ctc_loss(outputs, targets, input_lengths, target_lengths)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Decode the predicted sequence\n",
    "                _, predicted_indices = torch.max(outputs, 2)\n",
    "                predicted_indices = predicted_indices.permute(1, 0)\n",
    "\n",
    "                correct_characters = calculate_correct_characters(predicted_indices, targets)\n",
    "                total_correct_characters += correct_characters\n",
    "                total_characters += sum(target_lengths).item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            avg_correct_characters = total_correct_characters / total_characters if total_characters > 0 else 0\n",
    "\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Average Correct Characters: {avg_correct_characters:.4f}')\n",
    "\n",
    "        \n",
    "# Instantiate model and start training\n",
    "num_classes = len(dataset.char_to_idx) + 1\n",
    "model = CRNN(vocab_size=num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_ctc(model, train_loader, val_loader, optimizer, num_epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
